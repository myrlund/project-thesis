% Chapter 2

\chapter{Survey} % Main chapter title

\label{Chapter2} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 2. \emph{Survey}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------

% \emph{Review of relevant literature; review of similar software products or tools.}

\section{Relevant literature} % (fold)
\label{sec:relevant_literature}

The task of improving recommendations through sentiment analysis of social media data requires digging into several fields of study.

Some people have attempted the same task as in this thesis, albeit with another type of social data.
Singh et al. \cite{Singh2011} investigated a ``formulation, where [they] combined the content-based approach with a sentiment analysis task to improve the recommendation results.''
Their approach is very similar to our approach, but differs in two important ways:
\begin{enumerate}
  \item It uses user reviews from IMDB as content source\footnote{IMDB does not provide open API access at the time of writing.}, and not a more general source of sentiment-carrying content -- as in our case, with Twitter.
  \item It is not designed to enhance presupplied recommendations, but rather to generate its own based on genre input.
\end{enumerate}

As we're looking at data from Twitter, the sentiment analysis task is a bit different than usual, as it needs to operate on texts that are all less than 140 characters long. More often than not, we will in fact need to work with texts that are merely one or two sentences long.
Cho \& Kang \cite{ChoKang2012} ``propose a method of classifying tendencies and opinions in texts of multiple sentence length extracted from social media and covering both formal and informal vocabularies''.
Among the things the more unusual things they condider when analysing content is posision of each sentence and emotion icons, which is quite important in short, concise text like ones found on Twitter.
We'll be taking a closer look at this method for the actual sentiment analysis task.


% http://blog.datumbox.com/how-to-build-your-own-twitter-sentiment-analysis-tool/

\emph{@TODO More.}

% section relevant_literature (end)

\section{Similar applications} % (fold)
\label{sec:similar_applications}

What spawned the idea of using an unpersonal social service like Twitter as a content source for filtering content is that Netflix recently rolled out personal social recommendations of their content.
For this they use Facebook.

One huge limitation to the Facebook approach is that Facebook doesn't expose how ``close'' you are to your various friends.
% People influence each other in different ways.

Content sharing patterns (Social influence and the diffusion of user-created content): \cite{Bakshy2009}.

% section similar_applications (end)

%----------------------------------------------------------------------------------------

\section{Twitter data} % (fold)
\label{sec:twitter_data}



\emph{@TODO: Something about what terms we're searching for, using only title etc. Ref. implementation with filtered hashtags etc.}


% ----------------------------------------------------------------------------------------------------------------------

Micro-blogging services such as Twitter have enormous amounts of data on almost every topic imaginable.
Content is limited in length, and users react to each others' content by ``re-tweeting'', ``favoriting'' or ``replying to'' it.
This leaves us with a source of textual data that is:

\begin{description}
  \item[Instant] Users express reactions to events as they experience them.
  \item[Weighted] Users weigh each others' content by interacting with it.
  \item[Concise] Due to limitations on content length, users must express themselves concisely.
\end{description}

Furthermore, the Twitter search API\footnote{\url{https://dev.twitter.com/docs/api/1.1/get/search/tweets}} supports returning both \emph{popular} and \emph{recent} content, or \emph{a mix} of the two.
This enables two interesting approaches to both filtering and annotating the recommended content, in that we can treat popular and recent comments separately.

\subsection{What makes a Tweet ``popular''?}

As previously mentioned, ``Tweets'' can be \emph{favorited}, \emph{retweeted}, and \emph{replied to}.
Additionally, we can tell how big reach an author has by counting the number of \emph{followers} he/she has, and use this as another indication of content popularity.

We want to be able to use the data as a source of implicit ratings. To be able to, we need to quantify the significance of these verbs.
Oard~and~Kim~\cite{Oard98implicitfeedback,Oard01modelinginformation} and Kelly~and~Teevan~\cite{Kelly03implicitfeedback} have developed a framework for classification of implicit feedback.
They define three major categories for implicit feedback: examination, retention, and reference.

We adapt it to the domain of Twitter data, and wind up with table~\ref{tab:behavior_class}.

\begin{table}[h]
  \begin{center}
    \begin{tabular}{|llcl|}
      \hline
      \textbf{Original} & \textbf{Ours} & & \textbf{Action} \\
      \hline
      Examine   & Consume  & $\rightarrow$ & Follow \\
      \hline
      Annotate  & Evaluate & $\rightarrow$ & Reply \\
      \hline
      Retain    & Endorse  & $\rightarrow$ & Favorite \\
      \hline
      Reference & Forward  & $\rightarrow$ & Retweet \\
      \hline
    \end{tabular}
  \end{center}
  \caption{Classification of microblogging behavior}
  \label{tab:behavior_class}
\end{table}

% To clarify the classifications of table~\ref{tab:behavior_class}, let's break the terms down.
% 
% \begin{description}
%   \item[Tweet]
%     A user posts content to Twitter, in the form of a new post.
%     A Tweet can have a maximum of 140 characters.
%     Due to the size restrictions, tweets often contain links to websites.
%   \item[Follow]
%     Users consume each others' content by following each other.
%     The number of followers users have range from 0 to more than 40 million.
%     Following is a one-way relationship, and there is often a big difference in the number of users following and being followed by a user.
%   \item[Reply]
%     Users can mention each other in tweets by prepending a username with ``@''.
%     This same mechanism is used to reply to others' content.
%     When replying, the content the Tweet was replying to is stored along with the reply, forming a conversation tree.
%   \item[Favorite]
%     Users can favorite content, which notifies the content owner and boosts the content in search results etc.
%     It is also trivial to extract all content a particular user has favorited.
%   \item[Retweet]
%     When a user chooses to retweet content, that content is ``forwarded'' to the user's followers, and boosts the content in search results etc.
% \end{description}

Twitter does not, at the time of writing, allow querying of these qualities directly. However, they do have a concept of content popularity, and it's based off this set of qualities.

\subsection{Relevant parts of the Twitter API} % (fold)
\label{sub:relevant_parts_of_the_twitter_api}

The various endpoints in the Twitter REST API is divided into 16 categories:

\begin{enumerate}
  \item Timelines
  \item Tweets
  \item Search
  \item Streaming
  \item Direct Messages
  \item Friends & Followers
  \item Users
  \item Suggested Users
  \item Favorites
  \item Lists
  \item Saved Searches
  \item Places & Geo
  \item Trends
  \item Spam Reporting
  \item OAuth
  \item Help
\end{enumerate}

Of these, only two are of relevance, namely \emph{Search} and \emph{OAuth}.

OAuth is only relevant because it enables us to search, so we won't elaborate further on how we use it.

% subsection relevant_parts_of_the_twitter_api (end)

\subsection{Novelty of available data} % (fold)
\label{sub:novelty_of_available_data}

As briefly mentioned, part of the hypothesis is that Twitter data is usable for predicting ratings for new content, where collaborative filtering systems perform worse than otherwise.

Novelty, however, is an inherently fundamental quality of Twitter data, even as a data source.
The Twitter search API simply does not expose data more than about a week old.
As it is put in their search API guidelines as of December 2013~\cite{UsingTwitterSearchAPI}, ``The Search API is not complete index of all Tweets, but instead an index of recent Tweets. At the moment that index includes between 6-9 days of Tweets.''

This quality makes Twitter data less than useful when it comes to predicting ratings for movies old enough to have calmed in public debate -- a category which, not surprisingly, includes the vast majority of available movies.

% subsection novelty_of_available_data (end)

\subsection{Twitter as a Data Source} % (fold)
\label{sub:twitter_as_a_data_source}

There are vast opportunities in managing to understand a data source with the qualities discussed above, but alas -- the diversity and free nature of Twitter as a publishing platform comes at a price: \emph{there is a lot of noise}.
That is not to say that there is little relevant information, but when the service is designed to have such a low threshold for contributing content, a low signal-to-noise ratio seems inevitable.
We will return to the issue of noise in chapter~\ref{sec:evaluating_against_netflix_rating_data}, where we try to evaluate correlations between movie titles in our test data and Tweets about the same titles.

This problem of finding content carrying relevant information turns out to perhaps be the biggest challenge of the entire study.

% subsection twitter_as_a_data_source (end)

% section twitter_data (end)

\section{The sentiment classifier} % (fold)
\label{sec:the_sentiment_classifier}



% section the_sentiment_classifier (end)
